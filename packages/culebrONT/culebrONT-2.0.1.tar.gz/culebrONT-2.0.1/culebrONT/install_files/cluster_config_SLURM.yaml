__default__:
    cpus-per-task : 4
    mem-per-cpu : 10G
    partition : PARTITION
    output: '{log.output}_cluster'
    error: '{log.error}_cluster'
    job-name : '{rule}.{wildcards}'

run_medaka_train:
    cpus-per-task : 8
    mem-per-cpu : 8G
    partition : PARTITION

run_medaka_consensus:
    cpus-per-task : 8
    mem-per-cpu : 8G
    partition : PARTITION

run_flye:
    cpus-per-task : 10
    mem-per-cpu : 15G

run_canu:
    cpus-per-task : 10
    mem-per-cpu : 25G

run_raven:
    cpus-per-task : 8
    mem-per-cpu : 15G

run_shasta:
    cpus-per-task : 8
    mem-per-cpu : 20G

run_smartdenovo:
    cpus-per-task : 8
    mem-per-cpu : 15G

run_miniasm:
    cpus-per-task : 8
    mem-per-cpu : 15G

run_minipolish:
    cpus-per-task : 8
    mem-per-cpu : 15G

run_circlator:
    cpus-per-task : 8
    mem-per-cpu : 8G

run_racon:
    cpus-per-task : 8
    mem-per-cpu : 8G

run_nanopolish:
    cpus-per-task : 8
    mem-per-cpu : 8G

run_kat:
    cpus-per-task : 1
    mem-per-cpu : 8G

rule_graph:
    output : 'slurm_logs/stdout/{rule}/rule_graph.o'
    error : 'slurm_logs/error/{rule}/rule_graph.e'
    job-name : '{rule}'

run_get_versions:
    output : 'slurm_logs/stdout/{rule}/run_get_versions.o'
    error : 'slurm_logs/error/{rule}/run_get_versions.e'
    job-name : '{rule}'

run_report_snakemake:
    output : 'slurm_logs/stdout/{rule}/run_report_snakemake.o'
    error : 'slurm_logs/error/{rule}/run_report_snakemake.e'
    job-name : '{rule}'

run_report:
    output : 'slurm_logs/stdout/{rule}/run_report.o'
    error : 'slurm_logs/error/{rule}/run_report.e'
    job-name : '{rule}'

#you can add nodelist option if you want force slurm into a particular node
#nodelist : nodeX
