{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Classification Metrics Spark Example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classification metrics are used to calculate the performance of binary predictors based on a binary target. They are used extensively in other Iguanas modules. This example shows how they can be applied in Spark and how to create your own."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Requirements"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To run, you'll need the following:\n",
    "\n",
    "* A dataset containing binary predictor columns and a binary target column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from iguanas.metrics.classification import Precision, Recall, FScore, Revenue\n",
    "\n",
    "import numpy as np\n",
    "import databricks.koalas as ks\n",
    "from typing import Union"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's create some dummy predictor columns and a binary target column. For this example, let's assume the dummy predictor columns represent rules that have been applied to a dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "y_pred_ks = ks.Series(np.random.randint(0, 2, 1000), name = 'A')\n",
    "y_preds_ks = ks.DataFrame(np.random.randint(0, 2, (1000, 5)), columns=[i for i in 'ABCDE'])\n",
    "y_ks = ks.Series(np.random.randint(0, 2, 1000), name = 'label')\n",
    "amounts_ks = ks.Series(np.random.randint(0, 1000, 1000), name = 'amounts')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "21/12/06 12:03:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/06 12:03:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/12/06 12:03:26 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "21/12/06 12:03:26 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Apply optimisation functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are currently four classification metrics available:\n",
    "\n",
    "* Precision score\n",
    "* Recall score\n",
    "* Fbeta score\n",
    "* Revenue\n",
    "\n",
    "**Note that the *FScore*, *Precision* or *Recall* classes are ~100 times faster on larger datasets compared to the same functions from Sklearn's *metrics* module. They also work with Koalas DataFrames, whereas the Sklearn functions do not.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instantiate class and run fit method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can run the `fit` method to calculate the optimisation metric for each column in the dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Precision score"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "precision = Precision()\n",
    "# Single predictor\n",
    "rule_precision_ks = precision.fit(y_preds=y_pred_ks, y_true=y_ks, sample_weight=None)\n",
    "# Multiple predictors\n",
    "rule_precisions_ks = precision.fit(y_preds=y_preds_ks, y_true=y_ks, sample_weight=None)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Recall score"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "recall = Recall()\n",
    "# Single predictor\n",
    "rule_recall_ks = recall.fit(y_preds=y_pred_ks, y_true=y_ks, sample_weight=None)\n",
    "# Multiple predictors\n",
    "rule_recalls_ks = recall.fit(y_preds=y_preds_ks, y_true=y_ks, sample_weight=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fbeta score (beta=1)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "f1 = FScore(beta=1)\n",
    "# Single predictor)\n",
    "rule_f1_ks = f1.fit(y_preds=y_pred_ks, y_true=y_ks, sample_weight=None)\n",
    "# Multiple predictors)\n",
    "rule_f1s_ks = f1.fit(y_preds=y_preds_ks, y_true=y_ks, sample_weight=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Revenue"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "rev = Revenue(y_type='Fraud', chargeback_multiplier=2)\n",
    "# Single predictor\n",
    "rule_rev_ks = rev.fit(y_preds=y_pred_ks, y_true=y_ks, sample_weight=amounts_ks)\n",
    "# Multiple predictors\n",
    "rule_revs_ks = rev.fit(y_preds=y_preds_ks, y_true=y_ks, sample_weight=amounts_ks)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outputs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `fit` method returns the optimisation metric defined by the class:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "rule_precision_ks, rule_precisions_ks"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.48214285714285715,\n",
       " array([0.4875717 , 0.47109208, 0.47645951, 0.48850575, 0.4251497 ]))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "rule_recall_ks, rule_recalls_ks"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.5051975051975052,\n",
       " array([0.53014553, 0.45738046, 0.52598753, 0.53014553, 0.44282744]))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "rule_f1_ks, rule_f1s_ks"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.4934010152284264,\n",
       " array([0.50796813, 0.46413502, 0.5       , 0.50847458, 0.43380855]))"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "rule_rev_ks, rule_revs_ks"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1991, array([ 15119, -14481,  11721,  25063, -74931]))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `fit` method can be fed into various Iguanas modules as an argument (wherever the `metric` parameter appears). For example, in the RuleGeneratorOpt module, you can set the metric used to optimise the rules using this methodology."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating your own optimisation function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Say we want to create a class which calculates the Positive likelihood ratio (TP rate/FP rate)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The main class structure involves having a `fit` method which has three arguments - the binary predictor(s), the binary target and any event specific weights to apply. This method should return a single numeric value."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "class PositiveLikelihoodRatio:\n",
    "    \n",
    "    def fit(self,             \n",
    "            y_preds: Union[ks.Series, ks.DataFrame], \n",
    "            y_true: ks.Series, \n",
    "            sample_weight: ks.Series) -> float:\n",
    "        \n",
    "        def _calc_plr(y_true, y_preds):\n",
    "            # Calculate TPR\n",
    "            tpr = (y_true * y_preds).sum() / y_true.sum()\n",
    "            # Calculate FPR\n",
    "            fpr = ((1 - y_true) * y_preds).sum()/(1 - y_true).sum()\n",
    "            return 0 if tpr == 0 or fpr == 0 else tpr/fpr\n",
    "        \n",
    "        # Set this option to allow calc of TPR/FPR on Koalas dataframes\n",
    "        with ks.option_context(\"compute.ops_on_diff_frames\", True):\n",
    "            if y_preds.ndim == 1:            \n",
    "                return _calc_plr(y_true, y_preds)\n",
    "            else:\n",
    "                plrs = np.empty(y_preds.shape[1])\n",
    "                for i, col in enumerate(y_preds.columns):                        \n",
    "                    plrs[i] = _calc_plr(y_true, y_preds[col])\n",
    "                return plrs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then apply the `fit` method to the dataset to check it works:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "plr = PositiveLikelihoodRatio()\n",
    "# Single predictor\n",
    "rule_plr_ks = plr.fit(y_preds=y_pred_ks, y_true=y_ks, sample_weight=None)\n",
    "# Multiple predictors\n",
    "rule_plrs_ks = plr.fit(y_preds=y_preds_ks, y_true=y_ks, sample_weight=None)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "rule_plr_ks, rule_plrs_ks"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1.004588142519177,\n",
       " array([1.02666243, 0.96105448, 0.98196952, 1.0305076 , 0.79801195]))"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, after instantiating the class, we can feed the `fit` method to a relevant Iguanas module (for example, we can feed the `fit` method to the `metric` parameter in the `BayesianOptimiser` class so that rules are generated which maximise the Positive Likelihood Ratio)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "----"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a5a22224d030f6805b27da964f50b3905be89918ca593f843e32c3b2a80fa84"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.9 64-bit ('iguanas_os_dev': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}